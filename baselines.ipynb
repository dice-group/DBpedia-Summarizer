{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers # for loading model\n",
    "!pip install sentencepiece # for tokenization in some cases (requires runtime reload after installation in colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language in ISO 639â€‘1 code\n",
    "# both abstracts and short absctracts should be in this language\n",
    "lang = 'en' # 'en', 'nl', 'fr'\n",
    "\n",
    "output_path = '/data/data_' + lang + '.csv' # path for saving final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read saved .csv files\n",
    "df = pd.read_csv(output_path)\n",
    "df = df.drop(columns=['Unnamed: 0']) # if dataframe was saved with index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T5 model\n",
    "\n",
    "- [Model description on HuggingFace](https://huggingface.co/t5-large)\n",
    "- [Paper](https://jmlr.org/papers/volume21/20-074/20-074.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load T5 model and tokenizer\n",
    "sum_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-large\")\n",
    "\n",
    "t5_summaries = [] # list for summaries\n",
    "\n",
    "for num in range(len(df)):\n",
    "    #if num % 100 == 0:\n",
    "    #    print(num, 'from', len(df))\n",
    "    text = df['abstract'].loc[num] # abstract in the num row \n",
    "    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True) # input abstract text\n",
    "    outputs = sum_model.generate(inputs[\"input_ids\"], max_length=100, min_length=40, length_penalty=4.0, num_beams=4, early_stopping=True) # generating summary\n",
    "    #print(tokenizer.decode(outputs[0])[6:-4])\n",
    "    t5_summaries.append(tokenizer.decode(outputs[0])[6:-4]) # save summary in the list\n",
    "\n",
    "# add generated summaries as a column in the dataframe\n",
    "df['T5'] = t5_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual BART\n",
    "\n",
    "- [Model description on HuggingFace](https://huggingface.co/facebook/mbart-large-50)\n",
    "- [Paper](https://arxiv.org/abs/2008.00401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load multilingual BART and tokenizer\n",
    "sum_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50\")\n",
    "\n",
    "bart_summaries = [] # list for summaries\n",
    "\n",
    "for num in range(len(df)):\n",
    "    #if num % 100 == 0:\n",
    "    #    print(num, 'from', len(df))\n",
    "    text = df['abstract'].loc[num] # abstract in the num row \n",
    "    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True) # input abstract text\n",
    "    outputs = sum_model.generate(inputs[\"input_ids\"], length_penalty=4.0, num_beams=4, early_stopping=True) # generating summary\n",
    "    #print(tokenizer.decode(outputs[0])[19:-4])\n",
    "    bart_summaries.append(tokenizer.decode(outputs[0])[19:-4])  # save summary in the list\n",
    "\n",
    "# add generated summaries as a column in the dataframe\n",
    "df['BART'] = bart_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BART CNN summarization model\n",
    "\n",
    "- [Model description on HuggingFace](https://huggingface.co/facebook/bart-large-cnn)\n",
    "- [Paper](https://arxiv.org/abs/1910.13461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CNN-trained BART model and tokenizer\n",
    "sum_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "bart_cnn_summaries = [] # list for summaries\n",
    "\n",
    "for num in range(len(df)):\n",
    "    #if num % 100 == 0:\n",
    "    #    print(num, 'from', len(df))\n",
    "    text = df['abstract'].loc[num] # abstract in the num row \n",
    "    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True) # input abstract text\n",
    "    outputs = sum_model.generate(inputs[\"input_ids\"], length_penalty=4.0, num_beams=4, early_stopping=True) # generating summary\n",
    "    #print(tokenizer.decode(outputs[0])[7:-4])\n",
    "    bart_cnn_summaries.append(tokenizer.decode(outputs[0])[7:-4]) # save summary in the list\n",
    "\n",
    "# add generated summaries as a column in the dataframe\n",
    "df['BART-CNN'] = bart_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/content/drive/MyDrive/DBpedia_sum/data/sum_' + lang + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
